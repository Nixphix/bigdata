# demonstrate how to import/export json file to/from hdfs

# download the file
cd ~/spark/dataset
wget --no-check-certificate https://raw.githubusercontent.com/nixphix/bigdata/master/spark/employees.json
less employees.json

# copy it to hdfs
hdfs dfs -mkdir pyspark/json
hdfs dfs -put employees.json pyspark/json
hdfs dfs -ls pyspark/json

# import sql context
from pyspark import SQLContext
sqlcon = SQLContext(sc)

# read json file with sql context object
employeesjson = sqlcon.jsonFile("/user/cloudera/pyspark/json/employees.json")
type(employeesjson) # check the data type of he collection

# print imported data
for row in employeesjson.collect():
    print row
    
# registed json data as temp table for sql style querying
employeesjson.registerTempTable("employees")
employeesdata = sqlcon.sql("select * from employees")
for row in employeesdata.collect():
    print row


